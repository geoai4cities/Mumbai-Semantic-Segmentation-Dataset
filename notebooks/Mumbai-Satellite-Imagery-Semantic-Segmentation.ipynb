{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Evaluating green cover and open spaces in informal settlements of Mumbai using deep learning"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Importing Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T13:16:42.566171Z","iopub.status.busy":"2022-03-09T13:16:42.565587Z","iopub.status.idle":"2022-03-09T13:16:45.361637Z","shell.execute_reply":"2022-03-09T13:16:45.360769Z","shell.execute_reply.started":"2022-03-09T13:16:42.566133Z"},"trusted":true},"outputs":[],"source":["import pickle\n","import visualkeras\n","from tqdm import tqdm\n","import numpy as np\n","import pandas as pd\n","import skimage\n","from skimage import io\n","import tifffile as tifi\n","from skimage.io import imread_collection\n","import albumentations as A\n","from IPython.display import SVG\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import seaborn as sns\n","from PIL import Image, ImageFont\n","from collections import defaultdict\n","import os, re, sys, random, shutil, cv2\n","\n","from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import *\n","from tensorflow.keras import backend as K\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras import applications, optimizers\n","from tensorflow.keras.applications import VGG16, VGG19, DenseNet121, InceptionResNetV2, ResNet50, MobileNetV2\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n","from tensorflow.keras.utils import model_to_dot, plot_model\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger, LearningRateScheduler, TensorBoard"]},{"cell_type":"markdown","metadata":{},"source":["# Working with the Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:50:51.469924Z","iopub.status.busy":"2022-03-09T07:50:51.469686Z","iopub.status.idle":"2022-03-09T07:50:51.475025Z","shell.execute_reply":"2022-03-09T07:50:51.474254Z","shell.execute_reply.started":"2022-03-09T07:50:51.469894Z"},"trusted":true},"outputs":[],"source":["data_dir = \"../Kaggle_Data/split_data_v8/\"\n","train_images = \"../Kaggle_Data/split_data_v8/train_images/\"\n","train_masks = \"../Kaggle_Data/split_data_v8/train_masks/\"\n","val_images = \"../Kaggle_Data/split_data_v8/val_images/\"\n","val_masks = \"../Kaggle_Data/split_data_v8/val_masks/\"\n","test_images = \"../Kaggle_Data/split_data_v8/test_images/\"\n","test_masks = \"../Kaggle_Data/split_data_v8/test_masks/\""]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:50:51.47707Z","iopub.status.busy":"2022-03-09T07:50:51.476545Z","iopub.status.idle":"2022-03-09T07:50:52.138901Z","shell.execute_reply":"2022-03-09T07:50:52.138136Z","shell.execute_reply.started":"2022-03-09T07:50:51.47703Z"},"trusted":true},"outputs":[],"source":["print('Number of images in training set: ', len(os.listdir(train_images+'train')))\n","print('Number of masks in training set: ', len(os.listdir(train_masks+'train')))\n","print('Number of images in validation set: ', len(os.listdir(val_images+'val')))\n","print('Number of masks in validation set: ', len(os.listdir(val_masks+'val')))\n","print('Number of images in testing set: ', len(os.listdir(test_images+'test')))\n","print('Number of masks in testing set: ', len(os.listdir(test_masks+'test')))"]},{"cell_type":"markdown","metadata":{},"source":["# Satellite Images and Semantic Segmentation Masks (Ground Truths)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:50:52.140401Z","iopub.status.busy":"2022-03-09T07:50:52.140131Z","iopub.status.idle":"2022-03-09T07:51:00.68134Z","shell.execute_reply":"2022-03-09T07:51:00.680585Z","shell.execute_reply.started":"2022-03-09T07:50:52.140365Z"},"trusted":true},"outputs":[],"source":["files = ['tile_1.0_1', 'tile_1.1_1', 'tile_3.7_4', 'tile_3.7_49', 'tile_4.34_74', 'tile_4.35_21', 'tile_5.18_60', 'tile_5.26_80', 'tile_6.10_45']\n","\n","def show_data(files, images_dir, masks_dir):\n","        fig, axs = plt.subplots(3, 6, figsize=(22, 12), constrained_layout=True)\n","        sns.set_style(\"ticks\")\n","        fig.suptitle('Training Set Images & Masks\\n', fontsize=18, fontweight='medium')\n","        idx = 0\n","        for i in range(3):\n","            for j in range(6):\n","                if j%2 == 0:\n","                    axs[i][j].imshow(cv2.resize(cv2.cvtColor(cv2.imread(f'{images_dir}train/{files[idx]}.tif'), cv2.COLOR_BGR2RGB),(128, 128)))\n","                    axs[i][j].set_title(f'Satellite Image: {files[idx]}.tif', fontdict = {'fontsize':14, 'fontweight':'medium'})\n","                    axs[i][j].grid(False)\n","                    axs[i][j].axis(True)\n","                elif j%2 != 0:\n","                    if (files[idx] in ['image_1', 'image_2', 'image_6']):\n","                        axs[i][j].imshow(cv2.resize(cv2.cvtColor(cv2.imread(f'{masks_dir}train/{files[idx]}.tif'), cv2.COLOR_BGR2RGB),(128, 128)))\n","                        axs[i][j].set_title(f'Ground Truth: {files[idx]}.tif', fontdict = {'fontsize':14, 'fontweight':'medium'})\n","                        axs[i][j].grid(False)\n","                        axs[i][j].axis(True)\n","                        idx += 1\n","                    else:\n","                        axs[i][j].imshow(cv2.resize(cv2.cvtColor(cv2.imread(f'{masks_dir}train/{files[idx]}.png'), cv2.COLOR_BGR2RGB),(128, 128)))\n","                        axs[i][j].set_title(f'Ground Truth: {files[idx]}.png', fontdict = {'fontsize':14, 'fontweight':'medium'})\n","                        axs[i][j].grid(False)\n","                        axs[i][j].axis(True)\n","                        idx += 1\n","                        \n","        plt.savefig('./Output/sample_data', facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 300)\n","        plt.show()\n","\n","show_data(files, train_images, train_masks)"]},{"cell_type":"markdown","metadata":{},"source":["# Reading RGB Color Codes for Labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:51:00.682683Z","iopub.status.busy":"2022-03-09T07:51:00.682413Z","iopub.status.idle":"2022-03-09T07:51:00.710809Z","shell.execute_reply":"2022-03-09T07:51:00.71013Z","shell.execute_reply.started":"2022-03-09T07:51:00.68265Z"},"trusted":true},"outputs":[],"source":["class_dict_df = pd.read_csv(f'{data_dir}class_dict.csv', index_col=False, skipinitialspace=True)\n","class_dict_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:51:00.712623Z","iopub.status.busy":"2022-03-09T07:51:00.712123Z","iopub.status.idle":"2022-03-09T07:51:00.727374Z","shell.execute_reply":"2022-03-09T07:51:00.726545Z","shell.execute_reply.started":"2022-03-09T07:51:00.712578Z"},"trusted":true},"outputs":[],"source":["label_names= list(class_dict_df.name)\n","label_codes = []\n","r= np.asarray(class_dict_df.r)\n","g= np.asarray(class_dict_df.g)\n","b= np.asarray(class_dict_df.b)\n","\n","for i in range(len(class_dict_df)):\n","    label_codes.append(tuple([r[i], g[i], b[i]]))\n","    \n","label_codes, label_names"]},{"cell_type":"markdown","metadata":{},"source":["# Create Useful Label & Code Conversion Dictionaries\n","\n","These will be used for:\n","\n","* One hot encoding the mask labels for model training\n","\n","* Decoding the predicted labels for interpretation and visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:51:00.731233Z","iopub.status.busy":"2022-03-09T07:51:00.731047Z","iopub.status.idle":"2022-03-09T07:51:00.735904Z","shell.execute_reply":"2022-03-09T07:51:00.735184Z","shell.execute_reply.started":"2022-03-09T07:51:00.73121Z"},"trusted":true},"outputs":[],"source":["code2id = {v:k for k,v in enumerate(label_codes)}\n","id2code = {k:v for k,v in enumerate(label_codes)}\n","\n","name2id = {v:k for k,v in enumerate(label_names)}\n","id2name = {k:v for k,v in enumerate(label_names)}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:51:00.738243Z","iopub.status.busy":"2022-03-09T07:51:00.737628Z","iopub.status.idle":"2022-03-09T07:51:00.747861Z","shell.execute_reply":"2022-03-09T07:51:00.746728Z","shell.execute_reply.started":"2022-03-09T07:51:00.738203Z"},"trusted":true},"outputs":[],"source":["id2code"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:51:00.749729Z","iopub.status.busy":"2022-03-09T07:51:00.749401Z","iopub.status.idle":"2022-03-09T07:51:00.758771Z","shell.execute_reply":"2022-03-09T07:51:00.757828Z","shell.execute_reply.started":"2022-03-09T07:51:00.749639Z"},"trusted":true},"outputs":[],"source":["id2name"]},{"cell_type":"markdown","metadata":{},"source":["# Define Functions for One Hot Encoding RGB Labels & Decoding Encoded Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:51:00.760476Z","iopub.status.busy":"2022-03-09T07:51:00.760197Z","iopub.status.idle":"2022-03-09T07:51:00.772278Z","shell.execute_reply":"2022-03-09T07:51:00.771387Z","shell.execute_reply.started":"2022-03-09T07:51:00.760415Z"},"trusted":true},"outputs":[],"source":["def rgb_to_onehot(rgb_image, colormap = id2code):\n","    '''Function to one hot encode RGB mask labels\n","        Inputs: \n","            rgb_image - image matrix (eg. 256 x 256 x 3 dimension numpy ndarray)\n","            colormap - dictionary of color to label id\n","        Output: One hot encoded image of dimensions (height x width x num_classes) where num_classes = len(colormap)\n","    '''\n","    num_classes = len(colormap)\n","    shape = rgb_image.shape[:2]+(num_classes,)\n","    encoded_image = np.zeros( shape, dtype=np.int8 )\n","    for i, cls in enumerate(colormap):\n","        encoded_image[:,:,i] = np.all(rgb_image.reshape( (-1,3) ) == colormap[i], axis=1).reshape(shape[:2])\n","    return encoded_image\n","\n","def onehot_to_rgb(onehot, colormap = id2code):\n","    '''Function to decode encoded mask labels\n","        Inputs: \n","            onehot - one hot encoded image matrix (height x width x num_classes)\n","            colormap - dictionary of color to label id\n","        Output: Decoded RGB image (height x width x 3) \n","    '''\n","    single_layer = np.argmax(onehot, axis=-1)\n","    output = np.zeros( onehot.shape[:2]+(3,) )\n","    for k in colormap.keys():\n","        output[single_layer==k] = colormap[k]\n","    return np.uint8(output)"]},{"cell_type":"markdown","metadata":{},"source":["# Creating Custom Image Data Generators\n","\n","## Defining Data Generators"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:51:00.774019Z","iopub.status.busy":"2022-03-09T07:51:00.773833Z","iopub.status.idle":"2022-03-09T07:51:00.783504Z","shell.execute_reply":"2022-03-09T07:51:00.782749Z","shell.execute_reply.started":"2022-03-09T07:51:00.773997Z"},"trusted":true},"outputs":[],"source":["# Normalizing only frame images, since masks contain label info\n","data_gen_args = dict(rescale=1./255)\n","mask_gen_args = dict()\n","\n","train_frames_datagen = ImageDataGenerator(**data_gen_args)\n","train_masks_datagen = ImageDataGenerator(**mask_gen_args)\n","val_frames_datagen = ImageDataGenerator(**data_gen_args)\n","val_masks_datagen = ImageDataGenerator(**mask_gen_args)\n","test_frames_datagen = ImageDataGenerator(**data_gen_args)\n","test_masks_datagen = ImageDataGenerator(**mask_gen_args)\n","\n","# Seed defined for aligning images and their masks\n","seed = 1"]},{"cell_type":"markdown","metadata":{},"source":["# Custom Image Data Generators for Creating Batches of Frames and Masks"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:51:00.786138Z","iopub.status.busy":"2022-03-09T07:51:00.78538Z","iopub.status.idle":"2022-03-09T07:51:00.804043Z","shell.execute_reply":"2022-03-09T07:51:00.803379Z","shell.execute_reply.started":"2022-03-09T07:51:00.786111Z"},"trusted":true},"outputs":[],"source":["def TrainAugmentGenerator(train_images_dir, train_masks_dir, seed = 1, batch_size = 8, target_size = (512, 512)):\n","    '''Train Image data generator\n","        Inputs: \n","            seed - seed provided to the flow_from_directory function to ensure aligned data flow\n","            batch_size - number of images to import at a time\n","            train_images_dir - train images directory\n","            train_masks_dir - train masks directory\n","            target_size - tuple of integers (height, width)\n","            \n","        Output: Decoded RGB image (height x width x 3) \n","    '''\n","    train_image_generator = train_frames_datagen.flow_from_directory(\n","    train_images_dir,\n","    batch_size = batch_size, \n","    seed = seed, \n","    target_size = target_size)\n","\n","    train_mask_generator = train_masks_datagen.flow_from_directory(\n","    train_masks_dir,\n","    batch_size = batch_size, \n","    seed = seed, \n","    target_size = target_size)\n","\n","    while True:\n","        X1i = train_image_generator.next()\n","        X2i = train_mask_generator.next()\n","        \n","        #One hot encoding RGB images\n","        mask_encoded = [rgb_to_onehot(X2i[0][x,:,:,:], id2code) for x in range(X2i[0].shape[0])]\n","        \n","        yield X1i[0], np.asarray(mask_encoded)\n","\n","def ValAugmentGenerator(val_images_dir, val_masks_dir, seed = 1, batch_size = 8, target_size = (512, 512)):\n","    '''Validation Image data generator\n","        Inputs: \n","            seed - seed provided to the flow_from_directory function to ensure aligned data flow\n","            batch_size - number of images to import at a time\n","            val_images_dir - validation images directory\n","            val_masks_dir - validation masks directory\n","            target_size - tuple of integers (height, width)\n","            \n","        Output: Decoded RGB image (height x width x 3) \n","    '''\n","    val_image_generator = val_frames_datagen.flow_from_directory(\n","    val_images_dir,\n","    batch_size = batch_size, \n","    seed = seed, \n","    target_size = target_size)\n","\n","\n","    val_mask_generator = val_masks_datagen.flow_from_directory(\n","    val_masks_dir,\n","    batch_size = batch_size, \n","    seed = seed, \n","    target_size = target_size)\n","\n","\n","    while True:\n","        X1i = val_image_generator.next()\n","        X2i = val_mask_generator.next()\n","        \n","        #One hot encoding RGB images\n","        mask_encoded = [rgb_to_onehot(X2i[0][x,:,:,:], id2code) for x in range(X2i[0].shape[0])]\n","        \n","        yield X1i[0], np.asarray(mask_encoded)\n","        \n","def TestAugmentGenerator(test_images_dir, test_masks_dir, seed = 1, batch_size = 8, target_size = (512, 512)):\n","    '''Validation Image data generator\n","        Inputs: \n","            seed - seed provided to the flow_from_directory function to ensure aligned data flow\n","            batch_size - number of images to import at a time\n","            test_images_dir - testing images directory\n","            test_masks_dir - testing masks directory\n","            target_size - tuple of integers (height, width)\n","            \n","        Output: Decoded RGB image (height x width x 3) \n","    '''\n","    test_image_generator = test_frames_datagen.flow_from_directory(\n","    test_images_dir,\n","    batch_size = batch_size, \n","    seed = seed, \n","    target_size = target_size)\n","\n","\n","    test_mask_generator = test_masks_datagen.flow_from_directory(\n","    test_masks_dir,\n","    batch_size = batch_size, \n","    seed = seed, \n","    target_size = target_size)\n","\n","\n","    while True:\n","        X1i = test_image_generator.next()\n","        X2i = test_mask_generator.next()\n","        \n","        #One hot encoding RGB images\n","        mask_encoded = [rgb_to_onehot(X2i[0][x,:,:,:], id2code) for x in range(X2i[0].shape[0])]\n","        \n","        yield X1i[0], np.asarray(mask_encoded)"]},{"cell_type":"markdown","metadata":{},"source":["# 1. DeepLabV3+ Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:51:00.805789Z","iopub.status.busy":"2022-03-09T07:51:00.805334Z","iopub.status.idle":"2022-03-09T07:51:00.825399Z","shell.execute_reply":"2022-03-09T07:51:00.82463Z","shell.execute_reply.started":"2022-03-09T07:51:00.805754Z"},"trusted":true},"outputs":[],"source":["batch_size = 32\n","num_train_samples = len(np.sort(os.listdir(train_images+'train')))\n","num_val_samples = len(np.sort(os.listdir(val_images+'val')))\n","steps_per_epoch = np.ceil(float(num_train_samples) / float(batch_size))\n","print('steps_per_epoch: ', steps_per_epoch)\n","validation_steps = np.ceil(float(num_val_samples) / (float(batch_size)))\n","print('validation_steps: ', validation_steps)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:51:00.827011Z","iopub.status.busy":"2022-03-09T07:51:00.826379Z","iopub.status.idle":"2022-03-09T07:51:00.832263Z","shell.execute_reply":"2022-03-09T07:51:00.831323Z","shell.execute_reply.started":"2022-03-09T07:51:00.826954Z"},"trusted":true},"outputs":[],"source":["def dice_coef(y_true, y_pred):\n","    return (2. * K.sum(y_true * y_pred) + 1.) / (K.sum(y_true) + K.sum(y_pred) + 1.)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:51:00.834343Z","iopub.status.busy":"2022-03-09T07:51:00.833461Z","iopub.status.idle":"2022-03-09T07:51:00.844336Z","shell.execute_reply":"2022-03-09T07:51:00.843587Z","shell.execute_reply.started":"2022-03-09T07:51:00.834304Z"},"trusted":true},"outputs":[],"source":["def class_accuracy(confusion: np.ndarray) -> np.ndarray:\n","    \"\"\"\n","    Return the per class accuracy from confusion matrix.\n","    Args:\n","        confusion: the confusion matrix between ground truth and predictions\n","    Returns:\n","        a vector representing the per class accuracy\n","    \"\"\"\n","    # extract the number of correct guesses from the diagonal\n","    preds_correct = np.sum(confusion * np.eye(len(confusion)), axis=-1)\n","    # extract the number of total values per class from ground truth\n","    trues = np.sum(confusion, axis=-1)\n","    # get per class accuracy by dividing correct by total\n","    return preds_correct / trues\n","\n","def iou(confusion: np.ndarray) -> np.ndarray:\n","    \"\"\"\n","    Return the per class Intersection over Union (I/U) from confusion matrix.\n","    Args:\n","        confusion: the confusion matrix between ground truth and predictions\n","    Returns:\n","        a vector representing the per class I/U\n","    Reference:\n","        https://en.wikipedia.org/wiki/Jaccard_index\n","    \"\"\"\n","    # get |intersection| (AND) from the diagonal of the confusion matrix\n","    intersection = (confusion * np.eye(len(confusion))).sum(axis=-1)\n","    # calculate the total ground truths and predictions per class\n","    preds = confusion.sum(axis=0)\n","    trues = confusion.sum(axis=-1)\n","    # get |union| (OR) from the predictions, ground truths, and intersection\n","    union = trues + preds - intersection\n","    # return the intersection over the union\n","    return intersection / union"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T08:44:36.608592Z","iopub.status.busy":"2022-03-09T08:44:36.608284Z","iopub.status.idle":"2022-03-09T08:44:36.628727Z","shell.execute_reply":"2022-03-09T08:44:36.626158Z","shell.execute_reply.started":"2022-03-09T08:44:36.608557Z"},"trusted":true},"outputs":[],"source":["\"\"\" Atrous Spatial Pyramid Pooling \"\"\"\n","def ASPP(inputs):\n","    shape = inputs.shape\n","\n","    y_pool = AveragePooling2D(pool_size=(shape[1], shape[2]), name='average_pooling')(inputs)\n","    y_pool = Conv2D(filters=256, kernel_size=1, padding='same', use_bias=False)(y_pool)\n","    y_pool = BatchNormalization(name=f'bn_1')(y_pool)\n","    y_pool = Activation('relu', name=f'relu_1')(y_pool)\n","    y_pool = UpSampling2D((shape[1], shape[2]), interpolation=\"bilinear\")(y_pool)\n","\n","    y_1 = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same', use_bias=False)(inputs)\n","    y_1 = BatchNormalization()(y_1)\n","    y_1 = Activation('relu')(y_1)\n","    \n","    y_6 = Conv2D(filters=256, kernel_size=3, dilation_rate=6, padding='same', use_bias=False)(inputs)\n","    y_6 = BatchNormalization()(y_6)\n","    y_6 = Activation('relu')(y_6)\n","    \n","    y_12 = Conv2D(filters=256, kernel_size=3, dilation_rate=12, padding='same', use_bias=False)(inputs)\n","    y_12 = BatchNormalization()(y_12)\n","    y_12 = Activation('relu')(y_12)\n","    \n","    y_18 = Conv2D(filters=256, kernel_size=3, dilation_rate=18, padding='same', use_bias=False)(inputs)\n","    y_18 = BatchNormalization()(y_18)\n","    y_18 = Activation('relu')(y_18)\n","    \n","    y = Concatenate()([y_pool, y_1, y_6, y_12, y_18])\n","\n","    y = Conv2D(filters=256, kernel_size=1, dilation_rate=1, padding='same', use_bias=False)(y)\n","    y = BatchNormalization()(y)\n","    y = Activation('relu')(y)\n","    \n","    return y\n","\n","def DeepLabV3Plus(shape, num_classes):\n","    \"\"\" Inputs \"\"\"\n","    inputs = Input(shape)\n","\n","    \"\"\" Pre-trained ResNet50 \"\"\"\n","    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n","\n","    \"\"\" Pre-trained ResNet50 Output \"\"\"\n","    image_features = base_model.get_layer('conv4_block6_out').output\n","    x_a = ASPP(image_features)\n","    x_a = UpSampling2D((4, 4), interpolation=\"bilinear\")(x_a)\n","\n","    \"\"\" Get low-level features \"\"\"\n","    x_b = base_model.get_layer('conv2_block2_out').output\n","    x_b = Conv2D(filters=48, kernel_size=1, padding='same', use_bias=False)(x_b)\n","    x_b = BatchNormalization()(x_b)\n","    x_b = Activation('relu')(x_b)\n","    \n","    x = Concatenate()([x_a, x_b])\n","\n","    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu',use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    \n","    x = Conv2D(filters=256, kernel_size=3, padding='same', activation='relu', use_bias=False)(x)\n","    x = BatchNormalization()(x)\n","    x = Activation('relu')(x)\n","    x = UpSampling2D((4, 4), interpolation=\"bilinear\")(x)\n","\n","    \"\"\" Outputs \"\"\"\n","    x = Dropout(0.2)(x)\n","    x = Conv2D(num_classes, (1, 1), name='output_layer', padding=\"same\")(x)\n","    x = Activation('softmax')(x)\n","\n","    \"\"\" Model \"\"\"\n","    model = Model(inputs=inputs, outputs=x)\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T08:44:37.473538Z","iopub.status.busy":"2022-03-09T08:44:37.472836Z","iopub.status.idle":"2022-03-09T08:44:39.764009Z","shell.execute_reply":"2022-03-09T08:44:39.763245Z","shell.execute_reply.started":"2022-03-09T08:44:37.473488Z"},"trusted":true},"outputs":[],"source":["K.clear_session()\n","\n","loss = tf.keras.losses.CategoricalCrossentropy()\n","deeplabv3plus = DeepLabV3Plus(shape = (128, 128, 3), num_classes = 7)\n","deeplabv3plus.compile(optimizer=Adam(learning_rate = 0.0001), loss=loss, metrics=[dice_coef, \"accuracy\"])\n","deeplabv3plus.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T08:44:40.102871Z","iopub.status.busy":"2022-03-09T08:44:40.102441Z","iopub.status.idle":"2022-03-09T08:44:41.242081Z","shell.execute_reply":"2022-03-09T08:44:41.241337Z","shell.execute_reply.started":"2022-03-09T08:44:40.102829Z"},"trusted":true},"outputs":[],"source":["color_map = defaultdict(dict)\n","color_map[Dropout]['fill'] = 'gray'\n","\n","font = ImageFont.truetype(\"./fonts/OpenSans-Semibold.ttf\", 32)\n","visualkeras.layered_view(deeplabv3plus, legend=True, font=font, to_file='./Output/deeplabv3plus_unet_architecture.png', color_map=color_map, draw_volume=False)"]},{"cell_type":"markdown","metadata":{},"source":["# DeepLabV3+ Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:02:17.837815Z","iopub.status.busy":"2022-01-23T12:02:17.837435Z","iopub.status.idle":"2022-01-23T12:02:17.845811Z","shell.execute_reply":"2022-01-23T12:02:17.844942Z","shell.execute_reply.started":"2022-01-23T12:02:17.837779Z"},"trusted":true},"outputs":[],"source":["def exponential_decay(lr0, s):\n","    def exponential_decay_fn(epoch):\n","        return lr0 * 0.1 **(epoch / s)\n","    return exponential_decay_fn\n","\n","exponential_decay_fn = exponential_decay(0.0001, 40)\n","\n","lr_scheduler = LearningRateScheduler(\n","    exponential_decay_fn,\n","    verbose=1\n",")\n","\n","checkpoint = ModelCheckpoint(\n","    filepath = './Output/deeplabv3plus.h5',\n","    save_best_only = True, \n","#     save_weights_only = False,\n","    monitor = 'val_loss', \n","    mode = 'auto', \n","    verbose = 1\n",")\n","\n","# earlystop = EarlyStopping(\n","#     monitor = 'val_loss', \n","#     min_delta = 0.001, \n","#     patience = 10, \n","#     mode = 'auto', \n","#     verbose = 1,\n","#     restore_best_weights = True\n","# )\n","\n","csvlogger = CSVLogger(\n","    filename= \"./Output/deeplabv3plus_training.csv\",\n","    separator = \",\",\n","    append = False\n",")\n","\n","callbacks = [checkpoint, csvlogger, lr_scheduler]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:02:17.849618Z","iopub.status.busy":"2022-01-23T12:02:17.849356Z","iopub.status.idle":"2022-01-23T12:14:50.901006Z","shell.execute_reply":"2022-01-23T12:14:50.900204Z","shell.execute_reply.started":"2022-01-23T12:02:17.849582Z"},"trusted":true},"outputs":[],"source":["history_1 = deeplabv3plus.fit(\n","    TrainAugmentGenerator(train_images_dir = train_images, train_masks_dir = train_masks, target_size = (128, 128)), \n","    steps_per_epoch = steps_per_epoch,\n","    validation_data = ValAugmentGenerator(val_images_dir = val_images, val_masks_dir = val_masks, target_size = (128, 128)), \n","    validation_steps = validation_steps, \n","    epochs = 40,\n","    callbacks = callbacks,\n","    use_multiprocessing = False,\n","    verbose = 1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:14:50.903643Z","iopub.status.busy":"2022-01-23T12:14:50.90339Z","iopub.status.idle":"2022-01-23T12:14:50.911444Z","shell.execute_reply":"2022-01-23T12:14:50.910348Z","shell.execute_reply.started":"2022-01-23T12:14:50.903609Z"},"trusted":true},"outputs":[],"source":["with open('./Output/trainHistoryDict_deeplabv3plus', 'wb') as file_pi:\n","    pickle.dump(history_1.history, file_pi)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:14:50.913364Z","iopub.status.busy":"2022-01-23T12:14:50.913035Z","iopub.status.idle":"2022-01-23T12:14:53.037392Z","shell.execute_reply":"2022-01-23T12:14:53.036748Z","shell.execute_reply.started":"2022-01-23T12:14:50.913327Z"},"trusted":true},"outputs":[],"source":["fig, ax = plt.subplots(2, 2, figsize=(20, 12))\n","ax = ax.ravel()\n","sns.set_style(\"ticks\")\n","metrics = ['Dice Coefficient', 'Accuracy', 'Loss', 'Learning Rate']\n","\n","for i, met in enumerate(['dice_coef', 'accuracy', 'loss', 'lr']): \n","    if met != 'lr':\n","        ax[i].plot(history_1.history[met], '-')\n","        ax[i].plot(history_1.history['val_' + met], '-')\n","        ax[i].set_title('{} vs Epochs'.format(metrics[i]), fontsize=16)\n","        ax[i].set_xlabel('Epochs', fontsize=12)\n","        ax[i].set_ylabel(metrics[i], fontsize=12)\n","#         ax[i].set_xticks(np.arange(0,100,4))\n","        ax[i].legend(['Train', 'Validation'])\n","        ax[i].xaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n","        ax[i].yaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n","    else:\n","        ax[i].plot(history_1.history[met], '-')\n","        ax[i].set_title('{} vs Epochs'.format(metrics[i]), fontsize=16)\n","        ax[i].set_xlabel('Epochs', fontsize=12)\n","        ax[i].set_ylabel(metrics[i], fontsize=12)\n","#         ax[i].set_xticks(np.arange(0,100,4))\n","        ax[i].xaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n","        ax[i].yaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n","        \n","plt.savefig('./Output/deeplabv3plus_metrics_plot.png', facecolor= 'w',transparent= False, bbox_inches= 'tight', dpi= 300)"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluating DeepLabV3+ Model on Test Set"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:14:53.039721Z","iopub.status.busy":"2022-01-23T12:14:53.039137Z","iopub.status.idle":"2022-01-23T12:14:53.044353Z","shell.execute_reply":"2022-01-23T12:14:53.04372Z","shell.execute_reply.started":"2022-01-23T12:14:53.03968Z"},"trusted":true},"outputs":[],"source":["testing_gen = TestAugmentGenerator(test_images_dir = test_images, test_masks_dir = test_masks, batch_size = 32, target_size = (128, 128))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:14:53.046194Z","iopub.status.busy":"2022-01-23T12:14:53.045503Z","iopub.status.idle":"2022-01-23T12:15:04.190148Z","shell.execute_reply":"2022-01-23T12:15:04.189364Z","shell.execute_reply.started":"2022-01-23T12:14:53.046154Z"},"trusted":true},"outputs":[],"source":["deeplabv3plus.load_weights(\"./Output/deeplabv3plus.h5\")\n","deeplabv3plus_eval = deeplabv3plus.evaluate(testing_gen, steps=21, return_dict=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:15:17.630479Z","iopub.status.busy":"2022-01-23T12:15:17.63022Z","iopub.status.idle":"2022-01-23T12:15:17.635152Z","shell.execute_reply":"2022-01-23T12:15:17.634068Z","shell.execute_reply.started":"2022-01-23T12:15:17.630451Z"},"trusted":true},"outputs":[],"source":["scores = {\n","    'deeplabv3plus': {},\n","    'vgg16_unet': {},\n","    'mobilenetv2_unet' : {}\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:15:18.176519Z","iopub.status.busy":"2022-01-23T12:15:18.176283Z","iopub.status.idle":"2022-01-23T12:15:18.180425Z","shell.execute_reply":"2022-01-23T12:15:18.179566Z","shell.execute_reply.started":"2022-01-23T12:15:18.176491Z"},"trusted":true},"outputs":[],"source":["scores['deeplabv3plus'] = deeplabv3plus_eval"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:15:20.449595Z","iopub.status.busy":"2022-01-23T12:15:20.449049Z","iopub.status.idle":"2022-01-23T12:15:47.286143Z","shell.execute_reply":"2022-01-23T12:15:47.285368Z","shell.execute_reply.started":"2022-01-23T12:15:20.449555Z"},"trusted":true},"outputs":[],"source":["Y_true_all_1, y_pred_all_1 = np.array([]), np.array([])\n","count = 0\n","\n","for i in range(21):\n","    batch_img, batch_mask = next(testing_gen)\n","    pred_all= deeplabv3plus.predict(batch_img)\n","    \n","    for j in range(0,np.shape(pred_all)[0]):\n","        count += 1\n","        true_msk = batch_mask[j]\n","        pred_msk = pred_all[j]\n","        Y_true = np.argmax(true_msk, axis=-1) # Convert one-hot to index\n","        y_pred = np.argmax(pred_msk, axis=-1) # Convert one-hot to index\n","\n","        Y_true_flat = Y_true.flatten()\n","        y_pred_flat = y_pred.flatten()\n","            \n","        Y_true_all_1 = np.append(Y_true_all_1, Y_true_flat)\n","        y_pred_all_1 = np.append(y_pred_all_1, y_pred_flat)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:15:47.287916Z","iopub.status.busy":"2022-01-23T12:15:47.287636Z","iopub.status.idle":"2022-01-23T12:15:47.296128Z","shell.execute_reply":"2022-01-23T12:15:47.295398Z","shell.execute_reply.started":"2022-01-23T12:15:47.287864Z"},"trusted":true},"outputs":[],"source":["print(Y_true_all_1.shape, y_pred_all_1.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:15:54.040771Z","iopub.status.busy":"2022-01-23T12:15:54.040105Z","iopub.status.idle":"2022-01-23T12:16:16.427453Z","shell.execute_reply":"2022-01-23T12:16:16.42669Z","shell.execute_reply.started":"2022-01-23T12:15:54.040732Z"},"trusted":true},"outputs":[],"source":["print(classification_report(Y_true_all_1, y_pred_all_1))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Accuracy:', accuracy_score(Y_true_all_1, y_pred_all_1))\n","print('Precision:', precision_score(Y_true_all_1, y_pred_all_1, average='weighted'))\n","print('Recall:', recall_score(Y_true_all_1, y_pred_all_1, average='weighted'))\n","print('F1 Score:', f1_score(Y_true_all_1, y_pred_all_1, average='weighted'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:16:27.556955Z","iopub.status.busy":"2022-01-23T12:16:27.556678Z","iopub.status.idle":"2022-01-23T12:16:43.4144Z","shell.execute_reply":"2022-01-23T12:16:43.413684Z","shell.execute_reply.started":"2022-01-23T12:16:27.556923Z"},"trusted":true},"outputs":[],"source":["cm_1 = confusion_matrix(Y_true_all_1, y_pred_all_1)\n","df_cm_1 = pd.DataFrame(cm_1, label_names, label_names)\n","fig, ax = plt.subplots(figsize=(14,12))\n","# sns.set(font_scale=1.4) # for label size\n","sns.heatmap(df_cm_1, annot=True, annot_kws={\"size\": 16}, cmap=plt.cm.YlGnBu)\n","plt.title('Confusion Matrix for DeepLabV3+ CNN\\n', fontsize=16)\n","plt.savefig('./Output/confusion_matrix_1.png', transparent= False, bbox_inches= 'tight', dpi= 300)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["per_class_iou_1 = iou(cm_1)\n","per_class_iou_1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:16:43.416286Z","iopub.status.busy":"2022-01-23T12:16:43.416024Z","iopub.status.idle":"2022-01-23T12:16:43.421647Z","shell.execute_reply":"2022-01-23T12:16:43.421002Z","shell.execute_reply.started":"2022-01-23T12:16:43.41625Z"},"trusted":true},"outputs":[],"source":["per_class_acc_1 = class_accuracy(cm_1)\n","per_class_acc_1"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:16:51.78262Z","iopub.status.busy":"2022-01-23T12:16:51.782082Z","iopub.status.idle":"2022-01-23T12:16:51.795694Z","shell.execute_reply":"2022-01-23T12:16:51.794879Z","shell.execute_reply.started":"2022-01-23T12:16:51.782577Z"},"trusted":true},"outputs":[],"source":["deeplabv3plus_class_acc = pd.DataFrame(zip(label_names, per_class_acc_1[:6].T), columns=['Class', 'Accuracy'])\n","deeplabv3plus_class_acc['F1'] = f1_score(Y_true_all_1, y_pred_all_1, average=None)[:6]\n","deeplabv3plus_class_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:17:42.110496Z","iopub.status.busy":"2022-01-23T12:17:42.110009Z","iopub.status.idle":"2022-01-23T12:17:43.001214Z","shell.execute_reply":"2022-01-23T12:17:43.000517Z","shell.execute_reply.started":"2022-01-23T12:17:42.110456Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(12, 7))\n","plt.title('Class-wise Accuracy of DeepLabV3+ CNN', fontsize=16)\n","sns.set_style(\"ticks\")\n","sns.barplot(x=\"Class\", y=\"Accuracy\", data=deeplabv3plus_class_acc, palette='turbo', alpha = 0.8)\n","plt.grid(axis='y', color = 'lightgray', linestyle='-', linewidth=0.8)\n","plt.savefig('./Output/deeplabv3plus_class_acc', facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 300)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Predictions on Test Set Using DeepLabV3+ Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:17:47.923734Z","iopub.status.busy":"2022-01-23T12:17:47.923308Z","iopub.status.idle":"2022-01-23T12:17:48.630047Z","shell.execute_reply":"2022-01-23T12:17:48.629048Z","shell.execute_reply.started":"2022-01-23T12:17:47.923696Z"},"trusted":true},"outputs":[],"source":["!mkdir ./Output/deeplabv3plus_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:17:49.053781Z","iopub.status.busy":"2022-01-23T12:17:49.053527Z","iopub.status.idle":"2022-01-23T12:20:30.309379Z","shell.execute_reply":"2022-01-23T12:20:30.308741Z","shell.execute_reply.started":"2022-01-23T12:17:49.053751Z"},"trusted":true},"outputs":[],"source":["count = 0\n","for i in range(5):\n","    batch_img,batch_mask = next(testing_gen)\n","    pred_all= deeplabv3plus.predict(batch_img)\n","    np.shape(pred_all)\n","    \n","    for j in range(0,np.shape(pred_all)[0]):\n","        count += 1\n","        fig = plt.figure(figsize=(20,8))\n","\n","        ax1 = fig.add_subplot(1,3,1)\n","        ax1.imshow(batch_img[j])\n","        ax1.set_title('Input Image', fontdict={'fontsize': 16, 'fontweight': 'medium'})\n","        ax1.set_xticks(np.arange(0, 129, 16))\n","        ax1.set_yticks(np.arange(0, 129, 16))\n","        ax1.grid(False)\n","\n","        ax2 = fig.add_subplot(1,3,2)\n","        ax2.set_title('Ground Truth Mask', fontdict={'fontsize': 16, 'fontweight': 'medium'})\n","        ax2.imshow(onehot_to_rgb(batch_mask[j],id2code))\n","        ax2.set_xticks(np.arange(0, 129, 16))\n","        ax2.set_yticks(np.arange(0, 129, 16))\n","        ax2.grid(False)\n","\n","        ax3 = fig.add_subplot(1,3,3)\n","        ax3.set_title('Predicted Mask', fontdict={'fontsize': 16, 'fontweight': 'medium'})\n","        ax3.imshow(onehot_to_rgb(pred_all[j],id2code))\n","        ax3.set_xticks(np.arange(0, 129, 16))\n","        ax3.set_yticks(np.arange(0, 129, 16))\n","        ax3.grid(False)\n","\n","        plt.savefig('./Output/deeplabv3plus_pred/deeplabv3plus_pred_{}.png'.format(count), facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 200)\n","        plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# 2. VGG16 Encoder Based UNet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:51:00.846612Z","iopub.status.busy":"2022-03-09T07:51:00.845563Z","iopub.status.idle":"2022-03-09T07:51:00.86026Z","shell.execute_reply":"2022-03-09T07:51:00.859487Z","shell.execute_reply.started":"2022-03-09T07:51:00.846573Z"},"trusted":true},"outputs":[],"source":["def conv_block(input, num_filters):\n","    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","\n","    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","    return x\n","\n","def decoder_block(input, skip_features, num_filters):\n","    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n","    x = Concatenate()([x, skip_features])\n","    x = conv_block(x, num_filters)\n","    return x\n","\n","def build_vgg16_unet(input_shape, num_classes):\n","    \"\"\" Input \"\"\"\n","    inputs = Input(input_shape)\n","\n","    \"\"\" Pre-trained VGG16 Model \"\"\"\n","    vgg16 = VGG16(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n","\n","    \"\"\" Encoder \"\"\"\n","    s1 = vgg16.get_layer(\"block1_conv2\").output         \n","    s2 = vgg16.get_layer(\"block2_conv2\").output         \n","    s3 = vgg16.get_layer(\"block3_conv3\").output         \n","    s4 = vgg16.get_layer(\"block4_conv3\").output         \n","\n","    \"\"\" Bridge \"\"\"\n","    b1 = vgg16.get_layer(\"block5_conv3\").output         \n","\n","    \"\"\" Decoder \"\"\"\n","    d1 = decoder_block(b1, s4, 512)                     \n","    d2 = decoder_block(d1, s3, 256)                     \n","    d3 = decoder_block(d2, s2, 128)                     \n","    d4 = decoder_block(d3, s1, 64)   \n","\n","    \"\"\" Dropout \"\"\"\n","    x1 = Dropout(0.4)(d4)\n","    \n","    \"\"\" Output \"\"\"\n","    outputs = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(d4)\n","    \n","    model = Model(inputs, outputs, name=\"VGG16_UNet\")\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:51:00.862315Z","iopub.status.busy":"2022-03-09T07:51:00.86158Z","iopub.status.idle":"2022-03-09T07:51:04.583748Z","shell.execute_reply":"2022-03-09T07:51:04.582967Z","shell.execute_reply.started":"2022-03-09T07:51:00.862276Z"},"trusted":true},"outputs":[],"source":["K.clear_session()\n","\n","loss = tf.keras.losses.CategoricalCrossentropy()\n","vgg16_unet = build_vgg16_unet(input_shape = (128, 128, 3), num_classes = 7)\n","vgg16_unet.compile(optimizer=Adam(learning_rate = 0.0001), loss=loss, metrics=[dice_coef, \"accuracy\"])\n","vgg16_unet.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:51:04.585288Z","iopub.status.busy":"2022-03-09T07:51:04.585033Z","iopub.status.idle":"2022-03-09T07:51:04.834807Z","shell.execute_reply":"2022-03-09T07:51:04.834088Z","shell.execute_reply.started":"2022-03-09T07:51:04.585244Z"},"trusted":true},"outputs":[],"source":["color_map = defaultdict(dict)\n","color_map[Dropout]['fill'] = 'gray'\n","\n","font = ImageFont.truetype(\"./fonts/OpenSans-Semibold.ttf\", 32)\n","visualkeras.layered_view(vgg16_unet, legend=True, font=font, to_file='./Output/vgg16_unet_architecture.png', color_map=color_map, draw_volume=False)"]},{"cell_type":"markdown","metadata":{},"source":["# VGG16 UNet Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:20:52.062941Z","iopub.status.busy":"2022-01-23T12:20:52.062383Z","iopub.status.idle":"2022-01-23T12:20:52.069575Z","shell.execute_reply":"2022-01-23T12:20:52.068777Z","shell.execute_reply.started":"2022-01-23T12:20:52.062884Z"},"trusted":true},"outputs":[],"source":["def exponential_decay(lr0, s):\n","    def exponential_decay_fn(epoch):\n","        return lr0 * 0.1 **(epoch / s)\n","    return exponential_decay_fn\n","\n","exponential_decay_fn = exponential_decay(0.0001, 40)\n","\n","lr_scheduler = LearningRateScheduler(\n","    exponential_decay_fn,\n","    verbose=1\n",")\n","\n","checkpoint = ModelCheckpoint(\n","    filepath = './Output/vgg16_unet.h5',\n","    save_best_only = True, \n","#     save_weights_only = False,\n","    monitor = 'val_loss', \n","    mode = 'auto', \n","    verbose = 1\n",")\n","\n","# earlystop = EarlyStopping(\n","#     monitor = 'val_loss', \n","#     min_delta = 0.001, \n","#     patience = 10, \n","#     mode = 'auto', \n","#     verbose = 1,\n","#     restore_best_weights = True\n","# )\n","\n","csvlogger = CSVLogger(\n","    filename= \"./Output/vgg16_unet_training.csv\",\n","    separator = \",\",\n","    append = False\n",")\n","\n","callbacks = [checkpoint, csvlogger, lr_scheduler]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:20:54.251876Z","iopub.status.busy":"2022-01-23T12:20:54.25135Z","iopub.status.idle":"2022-01-23T12:31:23.143474Z","shell.execute_reply":"2022-01-23T12:31:23.142669Z","shell.execute_reply.started":"2022-01-23T12:20:54.251835Z"},"trusted":true},"outputs":[],"source":["history_2 = vgg16_unet.fit(\n","    TrainAugmentGenerator(train_images_dir = train_images, train_masks_dir = train_masks, target_size = (128, 128)), \n","    steps_per_epoch = steps_per_epoch,\n","    validation_data = ValAugmentGenerator(val_images_dir = val_images, val_masks_dir = val_masks, target_size = (128, 128)), \n","    validation_steps = validation_steps, \n","    epochs = 40,\n","    callbacks = callbacks,\n","    use_multiprocessing = False,\n","    verbose = 1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:31:23.14604Z","iopub.status.busy":"2022-01-23T12:31:23.145761Z","iopub.status.idle":"2022-01-23T12:31:23.150473Z","shell.execute_reply":"2022-01-23T12:31:23.149804Z","shell.execute_reply.started":"2022-01-23T12:31:23.146003Z"},"trusted":true},"outputs":[],"source":["with open('./Output/trainHistoryDict_vgg16_unet', 'wb') as file_pi:\n","    pickle.dump(history_2.history, file_pi)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:31:27.524842Z","iopub.status.busy":"2022-01-23T12:31:27.524547Z","iopub.status.idle":"2022-01-23T12:31:29.674385Z","shell.execute_reply":"2022-01-23T12:31:29.67375Z","shell.execute_reply.started":"2022-01-23T12:31:27.524809Z"},"trusted":true},"outputs":[],"source":["fig, ax = plt.subplots(2, 2, figsize=(20, 12))\n","ax = ax.ravel()\n","sns.set_style(\"ticks\")\n","metrics = ['Dice Coefficient', 'Accuracy', 'Loss', 'Learning Rate']\n","\n","for i, met in enumerate(['dice_coef', 'accuracy', 'loss', 'lr']): \n","    if met != 'lr':\n","        ax[i].plot(history_2.history[met], '-')\n","        ax[i].plot(history_2.history['val_' + met], '-')\n","        ax[i].set_title('{} vs Epochs'.format(metrics[i]), fontsize=16)\n","        ax[i].set_xlabel('Epochs', fontsize=12)\n","        ax[i].set_ylabel(metrics[i], fontsize=12)\n","#         ax[i].set_xticks(np.arange(0,100,4))\n","        ax[i].legend(['Train', 'Validation'])\n","        ax[i].xaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n","        ax[i].yaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n","    else:\n","        ax[i].plot(history_2.history[met], '-')\n","        ax[i].set_title('{} vs Epochs'.format(metrics[i]), fontsize=16)\n","        ax[i].set_xlabel('Epochs', fontsize=12)\n","        ax[i].set_ylabel(metrics[i], fontsize=12)\n","#         ax[i].set_xticks(np.arange(0,100,4))\n","        ax[i].xaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n","        ax[i].yaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n","        \n","plt.savefig('./Output/vgg16_unet_metrics_plot.png', facecolor= 'w',transparent= False, bbox_inches= 'tight', dpi= 300)"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluating VGG16-UNet Model on Test Set"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:31:44.294963Z","iopub.status.busy":"2022-01-23T12:31:44.294353Z","iopub.status.idle":"2022-01-23T12:31:44.301675Z","shell.execute_reply":"2022-01-23T12:31:44.300691Z","shell.execute_reply.started":"2022-01-23T12:31:44.294918Z"},"trusted":true},"outputs":[],"source":["testing_gen = TestAugmentGenerator(test_images_dir = test_images, test_masks_dir = test_masks, batch_size = 32, target_size = (128, 128))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:31:45.070882Z","iopub.status.busy":"2022-01-23T12:31:45.070206Z","iopub.status.idle":"2022-01-23T12:31:55.930972Z","shell.execute_reply":"2022-01-23T12:31:55.930193Z","shell.execute_reply.started":"2022-01-23T12:31:45.070843Z"},"trusted":true},"outputs":[],"source":["vgg16_unet.load_weights(\"./Output/vgg16_unet.h5\")\n","vgg16_unet_eval = vgg16_unet.evaluate(testing_gen, steps=21, return_dict=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:32:02.900826Z","iopub.status.busy":"2022-01-23T12:32:02.900556Z","iopub.status.idle":"2022-01-23T12:32:02.905465Z","shell.execute_reply":"2022-01-23T12:32:02.904749Z","shell.execute_reply.started":"2022-01-23T12:32:02.900795Z"},"trusted":true},"outputs":[],"source":["scores['vgg16_unet'] = vgg16_unet_eval"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:32:04.942098Z","iopub.status.busy":"2022-01-23T12:32:04.941288Z","iopub.status.idle":"2022-01-23T12:32:31.55048Z","shell.execute_reply":"2022-01-23T12:32:31.549698Z","shell.execute_reply.started":"2022-01-23T12:32:04.942047Z"},"trusted":true},"outputs":[],"source":["Y_true_all_2, y_pred_all_2 = np.array([]), np.array([])\n","count = 0\n","\n","for i in range(21):\n","    batch_img, batch_mask = next(testing_gen)\n","    pred_all= vgg16_unet.predict(batch_img)\n","    \n","    for j in range(0,np.shape(pred_all)[0]):\n","        count += 1\n","        true_msk = batch_mask[j]\n","        pred_msk = pred_all[j]\n","        Y_true = np.argmax(true_msk, axis=-1) # Convert one-hot to index\n","        y_pred = np.argmax(pred_msk, axis=-1) # Convert one-hot to index\n","\n","        Y_true_flat = Y_true.flatten()\n","        y_pred_flat = y_pred.flatten()\n","            \n","        Y_true_all_2 = np.append(Y_true_all_2, Y_true_flat)\n","        y_pred_all_2 = np.append(y_pred_all_2, y_pred_flat)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:32:31.552344Z","iopub.status.busy":"2022-01-23T12:32:31.552103Z","iopub.status.idle":"2022-01-23T12:32:31.557031Z","shell.execute_reply":"2022-01-23T12:32:31.556311Z","shell.execute_reply.started":"2022-01-23T12:32:31.55231Z"},"trusted":true},"outputs":[],"source":["print(Y_true_all_2.shape, y_pred_all_2.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:32:31.558799Z","iopub.status.busy":"2022-01-23T12:32:31.558079Z","iopub.status.idle":"2022-01-23T12:32:54.671526Z","shell.execute_reply":"2022-01-23T12:32:54.670814Z","shell.execute_reply.started":"2022-01-23T12:32:31.558761Z"},"trusted":true},"outputs":[],"source":["print(classification_report(Y_true_all_2, y_pred_all_2))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Accuracy:', accuracy_score(Y_true_all_2, y_pred_all_2))\n","print('Precision:', precision_score(Y_true_all_2, y_pred_all_2, average='weighted'))\n","print('Recall:', recall_score(Y_true_all_2, y_pred_all_2, average='weighted'))\n","print('F1 Score:', f1_score(Y_true_all_2, y_pred_all_2, average='weighted'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Class-wise F1 Score\\n', f1_score(Y_true_all_2, y_pred_all_2, average=None))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:32:54.677829Z","iopub.status.busy":"2022-01-23T12:32:54.675932Z","iopub.status.idle":"2022-01-23T12:33:09.888422Z","shell.execute_reply":"2022-01-23T12:33:09.887705Z","shell.execute_reply.started":"2022-01-23T12:32:54.677787Z"},"trusted":true},"outputs":[],"source":["cm_2 = confusion_matrix(Y_true_all_2, y_pred_all_2)\n","df_cm_2 = pd.DataFrame(cm_2, label_names, label_names)\n","fig, ax = plt.subplots(figsize=(14,12))\n","sns.heatmap(df_cm_2, annot=True, annot_kws={\"size\": 16}, cmap=plt.cm.YlGnBu)\n","plt.title('Confusion Matrix for VGG16-UNet CNN\\n', fontsize=16)\n","plt.savefig('./Output/confusion_matrix_2.png', transparent= False, bbox_inches= 'tight', dpi= 300)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:33:09.889972Z","iopub.status.busy":"2022-01-23T12:33:09.889625Z","iopub.status.idle":"2022-01-23T12:33:09.896523Z","shell.execute_reply":"2022-01-23T12:33:09.895636Z","shell.execute_reply.started":"2022-01-23T12:33:09.889936Z"},"trusted":true},"outputs":[],"source":["per_class_acc_2 = class_accuracy(cm_2)\n","per_class_acc_2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:33:21.887982Z","iopub.status.busy":"2022-01-23T12:33:21.887665Z","iopub.status.idle":"2022-01-23T12:33:21.898138Z","shell.execute_reply":"2022-01-23T12:33:21.897454Z","shell.execute_reply.started":"2022-01-23T12:33:21.887954Z"},"trusted":true},"outputs":[],"source":["vgg16_unet_class_acc = pd.DataFrame(zip(label_names, per_class_acc_2[:6].T), columns=['Class', 'Accuracy'])\n","vgg16_unet_class_acc['F1'] = f1_score(Y_true_all_2, y_pred_all_2, average=None)[:6]\n","vgg16_unet_class_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:33:33.879042Z","iopub.status.busy":"2022-01-23T12:33:33.878312Z","iopub.status.idle":"2022-01-23T12:33:34.549038Z","shell.execute_reply":"2022-01-23T12:33:34.548336Z","shell.execute_reply.started":"2022-01-23T12:33:33.878999Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(12, 7))\n","plt.title('Class-wise Accuracy of VGG16-UNet CNN', fontsize=16)\n","sns.set_style(\"ticks\")\n","sns.barplot(x=\"Class\", y=\"Accuracy\", data=vgg16_unet_class_acc, palette='turbo', alpha = 0.8)\n","plt.grid(axis='y', color = 'lightgray', linestyle='-', linewidth=0.8)\n","plt.savefig('./Output/vgg16_unet_class_acc', facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 300)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Predictions on Test Set Using VGG16 UNet Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:33:44.138772Z","iopub.status.busy":"2022-01-23T12:33:44.138014Z","iopub.status.idle":"2022-01-23T12:33:44.896547Z","shell.execute_reply":"2022-01-23T12:33:44.895479Z","shell.execute_reply.started":"2022-01-23T12:33:44.138721Z"},"trusted":true},"outputs":[],"source":["!mkdir ./Output/vgg16_unet_pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["count = 0\n","for i in range(5):\n","    batch_img,batch_mask = next(testing_gen)\n","    pred_all= vgg16_unet.predict(batch_img)\n","    np.shape(pred_all)\n","    \n","    for j in range(0,np.shape(pred_all)[0]):\n","        count += 1\n","        fig = plt.figure(figsize=(20,8))\n","\n","        ax1 = fig.add_subplot(1,3,1)\n","        ax1.imshow(batch_img[j])\n","        # cv2.imwrite(f'./Output/vgg16_unet_pred/{count}_img.tif', cv2.cvtColor(batch_img[j], cv2.COLOR_BGR2RGB))\n","        plt.imsave(f'./Output/vgg16_unet_pred/{count}_img.png', batch_img[j])\n","        # tifi.imsave(f'./Output/vgg16_unet_pred/{count}_img.tif', batch_img[j])\n","        # cv2.imwrite(f'./Output/vgg16_unet_pred/{count}_img.png', cv2.convertScaleAbs(batch_img[j], alpha=(255.0)))\n","        ax1.set_title('Input Image', fontdict={'fontsize': 16, 'fontweight': 'medium'})\n","        ax1.set_xticks(np.arange(0, 129, 16))\n","        ax1.set_yticks(np.arange(0, 129, 16))\n","        ax1.grid(False)\n","\n","        ax2 = fig.add_subplot(1,3,2)\n","        ax2.set_title('Ground Truth Mask', fontdict={'fontsize': 16, 'fontweight': 'medium'})\n","        ax2.imshow(onehot_to_rgb(batch_mask[j],id2code))\n","        cv2.imwrite(f'./Output/vgg16_unet_pred/{count}_gt.png', cv2.cvtColor(onehot_to_rgb(batch_mask[j],id2code), cv2.COLOR_BGR2RGB))\n","        ax2.set_xticks(np.arange(0, 129, 16))\n","        ax2.set_yticks(np.arange(0, 129, 16))\n","        ax2.grid(False)\n","\n","        ax3 = fig.add_subplot(1,3,3)\n","        ax3.set_title('Predicted Mask', fontdict={'fontsize': 16, 'fontweight': 'medium'})\n","        ax3.imshow(onehot_to_rgb(pred_all[j],id2code))\n","        cv2.imwrite(f'./Output/vgg16_unet_pred/{count}_pred.png', cv2.cvtColor(onehot_to_rgb(pred_all[j],id2code), cv2.COLOR_BGR2RGB))\n","        ax3.set_xticks(np.arange(0, 129, 16))\n","        ax3.set_yticks(np.arange(0, 129, 16))\n","        ax3.grid(False)\n","\n","        # plt.savefig('./Output/vgg16_unet_pred/vgg16_unet_pred_{}.png'.format(count), facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 200)\n","        plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# 3. MobileNetV2 Encoder Based UNet"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T08:44:54.389286Z","iopub.status.busy":"2022-03-09T08:44:54.389021Z","iopub.status.idle":"2022-03-09T08:44:54.403119Z","shell.execute_reply":"2022-03-09T08:44:54.402338Z","shell.execute_reply.started":"2022-03-09T08:44:54.389258Z"},"trusted":true},"outputs":[],"source":["def conv_block(inputs, num_filters):\n","    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","\n","    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n","    x = BatchNormalization()(x)\n","    x = Activation(\"relu\")(x)\n","\n","    return x\n","\n","def decoder_block(inputs, skip, num_filters):\n","    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n","    x = Concatenate()([x, skip])\n","    x = conv_block(x, num_filters)\n","\n","    return x\n","\n","def build_mobilenetv2_unet(input_shape, num_classes):   \n","    \"\"\" Input \"\"\"\n","    inputs = Input(shape=input_shape)\n","\n","    \"\"\" Pre-trained MobileNetV2 \"\"\"\n","    encoder = MobileNetV2(include_top=False, weights=\"imagenet\",\n","        input_tensor=inputs, alpha=1.4)\n","\n","    \"\"\" Encoder \"\"\"\n","    s1 = encoder.get_layer(\"input_1\").output                \n","    s2 = encoder.get_layer(\"block_1_expand_relu\").output    \n","    s3 = encoder.get_layer(\"block_3_expand_relu\").output    \n","    s4 = encoder.get_layer(\"block_6_expand_relu\").output    \n","\n","    \"\"\" Bridge \"\"\"\n","    b1 = encoder.get_layer(\"block_13_expand_relu\").output   \n","\n","    \"\"\" Decoder \"\"\"\n","    d1 = decoder_block(b1, s4, 512)                         \n","    d2 = decoder_block(d1, s3, 256)                         \n","    d3 = decoder_block(d2, s2, 128)                         \n","    d4 = decoder_block(d3, s1, 64)                          \n","    \n","    \"\"\" Dropout \"\"\"\n","    x1 = Dropout(0.4)(d4)\n","    \n","    \"\"\" Output \"\"\"\n","    outputs = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(x1)\n","\n","    model = Model(inputs, outputs, name=\"MobileNetV2-UNet\")\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T08:44:56.242981Z","iopub.status.busy":"2022-03-09T08:44:56.242418Z","iopub.status.idle":"2022-03-09T08:44:57.941998Z","shell.execute_reply":"2022-03-09T08:44:57.941287Z","shell.execute_reply.started":"2022-03-09T08:44:56.242942Z"},"trusted":true},"outputs":[],"source":["K.clear_session()\n","\n","loss = tf.keras.losses.CategoricalCrossentropy()\n","mobilenetv2_unet = build_mobilenetv2_unet(input_shape = (128, 128, 3), num_classes = 7)\n","mobilenetv2_unet.compile(optimizer=Adam(learning_rate = 0.0001), loss=loss, metrics=[dice_coef, \"accuracy\"])\n","mobilenetv2_unet.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T08:44:58.859339Z","iopub.status.busy":"2022-03-09T08:44:58.859065Z","iopub.status.idle":"2022-03-09T08:44:59.428132Z","shell.execute_reply":"2022-03-09T08:44:59.427407Z","shell.execute_reply.started":"2022-03-09T08:44:58.859311Z"},"trusted":true},"outputs":[],"source":["color_map = defaultdict(dict)\n","color_map[Dropout]['fill'] = 'gray'\n","\n","font = ImageFont.truetype(\"./fonts/OpenSans-Semibold.ttf\", 32)\n","visualkeras.layered_view(mobilenetv2_unet, legend=True, font=font, to_file='./Output/mobilenetv2_unet_architecture.png', color_map=color_map, draw_volume=False)"]},{"cell_type":"markdown","metadata":{},"source":["# MobileNetV2-UNet Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T08:44:47.109066Z","iopub.status.busy":"2022-03-09T08:44:47.10844Z","iopub.status.idle":"2022-03-09T08:44:47.115909Z","shell.execute_reply":"2022-03-09T08:44:47.115099Z","shell.execute_reply.started":"2022-03-09T08:44:47.109022Z"},"trusted":true},"outputs":[],"source":["def exponential_decay(lr0, s):\n","    def exponential_decay_fn(epoch):\n","        return lr0 * 0.1 **(epoch / s)\n","    return exponential_decay_fn\n","\n","exponential_decay_fn = exponential_decay(0.0001, 40)\n","\n","lr_scheduler = LearningRateScheduler(\n","    exponential_decay_fn,\n","    verbose=1\n",")\n","\n","checkpoint = ModelCheckpoint(\n","    filepath = './Output/mobilenetv2_unet.h5',\n","    save_best_only = True, \n","#     save_weights_only = False,\n","    monitor = 'val_loss', \n","    mode = 'auto', \n","    verbose = 1\n",")\n","\n","# earlystop = EarlyStopping(\n","#     monitor = 'val_loss', \n","#     min_delta = 0.001, \n","#     patience = 10, \n","#     mode = 'auto', \n","#     verbose = 1,\n","#     restore_best_weights = True\n","# )\n","\n","csvlogger = CSVLogger(\n","    filename= \"./Output/mobilenetv2_unet_training.csv\",\n","    separator = \",\",\n","    append = False\n",")\n","\n","callbacks = [checkpoint, csvlogger, lr_scheduler]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:37:21.097508Z","iopub.status.busy":"2022-01-23T12:37:21.096788Z","iopub.status.idle":"2022-01-23T12:46:51.924709Z","shell.execute_reply":"2022-01-23T12:46:51.923947Z","shell.execute_reply.started":"2022-01-23T12:37:21.097468Z"},"trusted":true},"outputs":[],"source":["history_3 = mobilenetv2_unet.fit(\n","    TrainAugmentGenerator(train_images_dir = train_images, train_masks_dir = train_masks, target_size = (128, 128)), \n","    steps_per_epoch = steps_per_epoch,\n","    validation_data = ValAugmentGenerator(val_images_dir = val_images, val_masks_dir = val_masks, target_size = (128, 128)), \n","    validation_steps = validation_steps, \n","    epochs = 40,\n","    callbacks = callbacks,\n","    use_multiprocessing = False,\n","    verbose = 1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:46:51.927137Z","iopub.status.busy":"2022-01-23T12:46:51.926858Z","iopub.status.idle":"2022-01-23T12:46:51.933788Z","shell.execute_reply":"2022-01-23T12:46:51.933039Z","shell.execute_reply.started":"2022-01-23T12:46:51.9271Z"},"trusted":true},"outputs":[],"source":["with open('./Output/trainHistoryDict_mobilenetv2_unet', 'wb') as file_pi:\n","    pickle.dump(history_3.history, file_pi)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:46:51.936729Z","iopub.status.busy":"2022-01-23T12:46:51.936524Z","iopub.status.idle":"2022-01-23T12:46:54.045401Z","shell.execute_reply":"2022-01-23T12:46:54.044725Z","shell.execute_reply.started":"2022-01-23T12:46:51.936705Z"},"trusted":true},"outputs":[],"source":["fig, ax = plt.subplots(2, 2, figsize=(20, 12))\n","ax = ax.ravel()\n","sns.set_style(\"ticks\")\n","\n","metrics = ['Dice Coefficient', 'Accuracy', 'Loss', 'Learning Rate']\n","\n","for i, met in enumerate(['dice_coef', 'accuracy', 'loss', 'lr']): \n","    if met != 'lr':\n","        ax[i].plot(history_3.history[met], '-')\n","        ax[i].plot(history_3.history['val_' + met], '-')\n","        ax[i].set_title('{} vs Epochs'.format(metrics[i]), fontsize=16)\n","        ax[i].set_xlabel('Epochs', fontsize=12)\n","        ax[i].set_ylabel(metrics[i], fontsize=12)\n","#         ax[i].set_xticks(np.arange(0,100,4))\n","        ax[i].legend(['Train', 'Validation'])\n","        ax[i].xaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n","        ax[i].yaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n","    else:\n","        ax[i].plot(history_3.history[met], '-')\n","        ax[i].set_title('{} vs Epochs'.format(metrics[i]), fontsize=16)\n","        ax[i].set_xlabel('Epochs', fontsize=12)\n","        ax[i].set_ylabel(metrics[i], fontsize=12)\n","#         ax[i].set_xticks(np.arange(0,100,4))\n","        ax[i].xaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n","        ax[i].yaxis.grid(True, color = \"lightgray\", linewidth = \"0.8\", linestyle = \"-\")\n","        \n","plt.savefig('./Output/mobilenetv2_unet_metrics_plot.png', facecolor= 'w',transparent= False, bbox_inches= 'tight', dpi= 300)"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluating MobileNetV2-UNet Model on Test Set"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-05T13:07:15.226087Z","iopub.status.busy":"2022-03-05T13:07:15.225524Z","iopub.status.idle":"2022-03-05T13:07:15.230948Z","shell.execute_reply":"2022-03-05T13:07:15.230108Z","shell.execute_reply.started":"2022-03-05T13:07:15.226035Z"},"trusted":true},"outputs":[],"source":["testing_gen = TestAugmentGenerator(test_images_dir = test_images, test_masks_dir = test_masks, batch_size = 32, target_size = (128, 128))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:46:54.054371Z","iopub.status.busy":"2022-01-23T12:46:54.053557Z","iopub.status.idle":"2022-01-23T12:47:00.256071Z","shell.execute_reply":"2022-01-23T12:47:00.255307Z","shell.execute_reply.started":"2022-01-23T12:46:54.054328Z"},"trusted":true},"outputs":[],"source":["mobilenetv2_unet.load_weights(\"./Output/mobilenetv2_unet.h5\")\n","mobilenetv2_unet_eval = mobilenetv2_unet.evaluate(testing_gen, steps=21, return_dict=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:47:17.022462Z","iopub.status.busy":"2022-01-23T12:47:17.021875Z","iopub.status.idle":"2022-01-23T12:47:17.026014Z","shell.execute_reply":"2022-01-23T12:47:17.025313Z","shell.execute_reply.started":"2022-01-23T12:47:17.022422Z"},"trusted":true},"outputs":[],"source":["scores['mobilenetv2_unet'] = mobilenetv2_unet_eval"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:47:19.224182Z","iopub.status.busy":"2022-01-23T12:47:19.223368Z","iopub.status.idle":"2022-01-23T12:47:44.99917Z","shell.execute_reply":"2022-01-23T12:47:44.998413Z","shell.execute_reply.started":"2022-01-23T12:47:19.224131Z"},"trusted":true},"outputs":[],"source":["Y_true_all_3, y_pred_all_3 = np.array([]), np.array([])\n","count = 0\n","\n","for i in range(21):\n","    batch_img, batch_mask = next(testing_gen)\n","    pred_all= mobilenetv2_unet.predict(batch_img)\n","    \n","    for j in range(0,np.shape(pred_all)[0]):\n","        count += 1\n","        true_msk = batch_mask[j]\n","        pred_msk = pred_all[j]\n","        Y_true = np.argmax(true_msk, axis=-1) # Convert one-hot to index\n","        y_pred = np.argmax(pred_msk, axis=-1) # Convert one-hot to index\n","\n","        Y_true_flat = Y_true.flatten()\n","        y_pred_flat = y_pred.flatten()\n","            \n","        Y_true_all_3 = np.append(Y_true_all_3, Y_true_flat)\n","        y_pred_all_3 = np.append(y_pred_all_3, y_pred_flat)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:47:45.001048Z","iopub.status.busy":"2022-01-23T12:47:45.000786Z","iopub.status.idle":"2022-01-23T12:47:45.006772Z","shell.execute_reply":"2022-01-23T12:47:45.005974Z","shell.execute_reply.started":"2022-01-23T12:47:45.001014Z"},"trusted":true},"outputs":[],"source":["print(Y_true_all_3.shape, y_pred_all_3.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Accuracy:', accuracy_score(Y_true_all_3, y_pred_all_3))\n","print('Precision:', precision_score(Y_true_all_3, y_pred_all_3, average='weighted'))\n","print('Recall:', recall_score(Y_true_all_3, y_pred_all_3, average='weighted'))\n","print('F1 Score:', f1_score(Y_true_all_3, y_pred_all_3, average='weighted'))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:47:45.008983Z","iopub.status.busy":"2022-01-23T12:47:45.008185Z","iopub.status.idle":"2022-01-23T12:48:07.525091Z","shell.execute_reply":"2022-01-23T12:48:07.524046Z","shell.execute_reply.started":"2022-01-23T12:47:45.008947Z"},"trusted":true},"outputs":[],"source":["print(classification_report(Y_true_all_3, y_pred_all_3))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:48:07.530881Z","iopub.status.busy":"2022-01-23T12:48:07.527064Z","iopub.status.idle":"2022-01-23T12:48:23.138385Z","shell.execute_reply":"2022-01-23T12:48:23.13773Z","shell.execute_reply.started":"2022-01-23T12:48:07.530834Z"},"trusted":true},"outputs":[],"source":["cm_3 = confusion_matrix(Y_true_all_3, y_pred_all_3)\n","df_cm_3 = pd.DataFrame(cm_3, label_names, label_names)\n","fig, ax = plt.subplots(figsize=(14,12))\n","sns.heatmap(df_cm_3, annot=True, annot_kws={\"size\": 16}, cmap=plt.cm.YlGnBu)\n","plt.title('Confusion Matrix for MobileNetV2-UNet CNN\\n', fontsize=16)\n","plt.savefig('./Output/confusion_matrix_3.png', transparent= False, bbox_inches= 'tight', dpi= 300)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:48:23.140175Z","iopub.status.busy":"2022-01-23T12:48:23.139549Z","iopub.status.idle":"2022-01-23T12:48:23.146833Z","shell.execute_reply":"2022-01-23T12:48:23.14601Z","shell.execute_reply.started":"2022-01-23T12:48:23.140139Z"},"trusted":true},"outputs":[],"source":["per_class_acc_3 = class_accuracy(cm_3)\n","per_class_acc_3"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:48:39.59685Z","iopub.status.busy":"2022-01-23T12:48:39.596585Z","iopub.status.idle":"2022-01-23T12:48:39.607446Z","shell.execute_reply":"2022-01-23T12:48:39.606742Z","shell.execute_reply.started":"2022-01-23T12:48:39.596818Z"},"trusted":true},"outputs":[],"source":["mobilenetv2_unet_class_acc = pd.DataFrame(zip(label_names, per_class_acc_3[:6].T), columns=['Class', 'Accuracy'])\n","mobilenetv2_unet_class_acc['F1'] = f1_score(Y_true_all_3, y_pred_all_3, average=None)[:6]\n","mobilenetv2_unet_class_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:48:58.18115Z","iopub.status.busy":"2022-01-23T12:48:58.180684Z","iopub.status.idle":"2022-01-23T12:48:58.836403Z","shell.execute_reply":"2022-01-23T12:48:58.835716Z","shell.execute_reply.started":"2022-01-23T12:48:58.181113Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(12, 7))\n","plt.title('Class-wise Accuracy of MobileNetV2-UNet CNN', fontsize=16)\n","sns.set_style(\"ticks\")\n","sns.barplot(x=\"Class\", y=\"Accuracy\", data=mobilenetv2_unet_class_acc, palette='turbo', alpha = 0.8)\n","plt.grid(axis='y', color = 'lightgray', linestyle='-', linewidth=0.8)\n","plt.savefig('./Output/mobilenetv2_unet_class_acc', facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 300)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Predictions on Test Set Using MobileNetV2-UNet Model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:50:26.554419Z","iopub.status.busy":"2022-01-23T12:50:26.553733Z","iopub.status.idle":"2022-01-23T12:50:27.265394Z","shell.execute_reply":"2022-01-23T12:50:27.264399Z","shell.execute_reply.started":"2022-01-23T12:50:26.55438Z"},"trusted":true},"outputs":[],"source":["!mkdir mobilenetv2_unet_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-01-23T12:50:27.824586Z","iopub.status.busy":"2022-01-23T12:50:27.824023Z","iopub.status.idle":"2022-01-23T12:53:10.979886Z","shell.execute_reply":"2022-01-23T12:53:10.979218Z","shell.execute_reply.started":"2022-01-23T12:50:27.824544Z"},"trusted":true},"outputs":[],"source":["count = 0\n","for i in range(5):\n","    batch_img,batch_mask = next(testing_gen)\n","    pred_all= mobilenetv2_unet.predict(batch_img)\n","    np.shape(pred_all)\n","    \n","    for j in range(0,np.shape(pred_all)[0]):\n","        count += 1\n","        fig = plt.figure(figsize=(20,8))\n","\n","        ax1 = fig.add_subplot(1,3,1)\n","        ax1.imshow(batch_img[j])\n","        ax1.set_title('Input Image', fontdict={'fontsize': 16, 'fontweight': 'medium'})\n","        ax1.set_xticks(np.arange(0, 129, 16))\n","        ax1.set_yticks(np.arange(0, 129, 16))\n","        ax1.grid(False)\n","\n","        ax2 = fig.add_subplot(1,3,2)\n","        ax2.set_title('Ground Truth Mask', fontdict={'fontsize': 16, 'fontweight': 'medium'})\n","        ax2.imshow(onehot_to_rgb(batch_mask[j],id2code))\n","        ax2.set_xticks(np.arange(0, 129, 16))\n","        ax2.set_yticks(np.arange(0, 129, 16))\n","        ax2.grid(False)\n","\n","        ax3 = fig.add_subplot(1,3,3)\n","        ax3.set_title('Predicted Mask', fontdict={'fontsize': 16, 'fontweight': 'medium'})\n","        ax3.imshow(onehot_to_rgb(pred_all[j],id2code))\n","        ax3.set_xticks(np.arange(0, 129, 16))\n","        ax3.set_yticks(np.arange(0, 129, 16))\n","        ax3.grid(False)\n","\n","        plt.savefig('./Output/mobilenetv2_unet_pred/mobilenetv2_unet_pred_{}.png'.format(count), facecolor= 'w', transparent= False, bbox_inches= 'tight', dpi= 200)\n","        plt.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Predict on Whole Satellite Imagery"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:51:48.988178Z","iopub.status.busy":"2022-03-09T07:51:48.987884Z","iopub.status.idle":"2022-03-09T07:51:48.992309Z","shell.execute_reply":"2022-03-09T07:51:48.99131Z","shell.execute_reply.started":"2022-03-09T07:51:48.988146Z"},"trusted":true},"outputs":[],"source":["tiles_dir = '../Mumbai_Data/jp22/jp22/'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:51:50.437587Z","iopub.status.busy":"2022-03-09T07:51:50.437099Z","iopub.status.idle":"2022-03-09T07:51:50.445154Z","shell.execute_reply":"2022-03-09T07:51:50.44405Z","shell.execute_reply.started":"2022-03-09T07:51:50.437544Z"},"trusted":true},"outputs":[],"source":["def predict_on_tiles(tiles_dir, model, save_dir):\n","    files = os.listdir(tiles_dir)\n","    for tile in tqdm(files, desc=\"[Predicting…]\", ascii=False, ncols=75):\n","        img = cv2.cvtColor(cv2.imread(f'{tiles_dir}{tile}'), cv2.COLOR_BGR2RGB)\n","        img = np.array(img).astype('float32')/255\n","        img = np.expand_dims(img, axis=0)\n","        pred_img = model.predict(img)\n","        pred_img = onehot_to_rgb(pred_img[0],id2code)\n","        pred_filename = tile.split('.tif')[0]\n","        cv2.imwrite(f'{save_dir}{pred_filename}.png', cv2.cvtColor(pred_img, cv2.COLOR_BGR2RGB))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T08:39:17.066243Z","iopub.status.busy":"2022-03-09T08:39:17.065396Z","iopub.status.idle":"2022-03-09T08:39:17.073415Z","shell.execute_reply":"2022-03-09T08:39:17.072516Z","shell.execute_reply.started":"2022-03-09T08:39:17.0662Z"},"trusted":true},"outputs":[],"source":["def stitch_tiles(pred_tiles_dir, save_filename, save_dir):\n","#     !mkdir hconcat_tiles\n","    img_list = imread_collection(f'{pred_tiles_dir}*.png')\n","    j = 0\n","    for i in range(0, len(os.listdir(pred_tiles_dir)), 285):\n","        img = cv2.hconcat(img_list[i:i+285])\n","        cv2.imwrite(f'{save_dir}hconcat_tile_{j}.png', cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n","        j += 1\n","                   \n","    hconcat_imgs = imread_collection(f'{save_dir}*.png')\n","    final_pred_tile = cv2.vconcat(hconcat_imgs)\n","    cv2.imwrite(f'{save_filename}.png', cv2.cvtColor(final_pred_tile, cv2.COLOR_BGR2RGB))\n","    return final_pred_tile\n","        "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 1. DeepLabV3+ Semantic Map Prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T08:45:25.452245Z","iopub.status.busy":"2022-03-09T08:45:25.451982Z","iopub.status.idle":"2022-03-09T08:45:26.20996Z","shell.execute_reply":"2022-03-09T08:45:26.20894Z","shell.execute_reply.started":"2022-03-09T08:45:25.452214Z"},"trusted":true},"outputs":[],"source":["!mkdir deeplabv3plus_pred_tiles"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T08:45:26.253911Z","iopub.status.busy":"2022-03-09T08:45:26.253311Z","iopub.status.idle":"2022-03-09T08:45:27.447551Z","shell.execute_reply":"2022-03-09T08:45:27.446775Z","shell.execute_reply.started":"2022-03-09T08:45:26.253873Z"},"trusted":true},"outputs":[],"source":["deeplabv3plus.load_weights(\"./Output/deeplabv3plus.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T15:51:21.41673Z","iopub.status.busy":"2022-03-07T15:51:21.416241Z","iopub.status.idle":"2022-03-07T15:53:22.208815Z","shell.execute_reply":"2022-03-07T15:53:22.204784Z","shell.execute_reply.started":"2022-03-07T15:51:21.416681Z"},"trusted":true},"outputs":[],"source":["predict_on_tiles(tiles_dir=tiles_dir, model=deeplabv3plus, save_dir='./deeplabv3plus_pred_tiles/')"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2022-03-07T15:54:12.526462Z","iopub.status.busy":"2022-03-07T15:54:12.526099Z","iopub.status.idle":"2022-03-07T15:54:14.485041Z","shell.execute_reply":"2022-03-07T15:54:14.48368Z","shell.execute_reply.started":"2022-03-07T15:54:12.526394Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["!zip -r deeplabv3plus_pred_tiles.zip './deeplabv3plus_pred_tiles'\n","!mkdir deeplabv3plus_stitched_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T15:55:13.039182Z","iopub.status.busy":"2022-03-07T15:55:13.038496Z","iopub.status.idle":"2022-03-07T15:55:15.424932Z","shell.execute_reply":"2022-03-07T15:55:15.423953Z","shell.execute_reply.started":"2022-03-07T15:55:13.039116Z"},"trusted":true},"outputs":[],"source":["deeplabv3plus_tile = stitch_tiles(pred_tiles_dir='./deeplabv3plus_pred_tiles/', save_filename='deeplabv3plus_jp22', save_dir='./deeplabv3plus_stitched_pred/')"]},{"cell_type":"markdown","metadata":{},"source":["## VGG16-UNet Semantic Maps Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:52:02.478211Z","iopub.status.busy":"2022-03-09T07:52:02.477429Z","iopub.status.idle":"2022-03-09T07:52:03.397456Z","shell.execute_reply":"2022-03-09T07:52:03.396381Z","shell.execute_reply.started":"2022-03-09T07:52:02.478171Z"},"trusted":true},"outputs":[],"source":["!mkdir vgg16_unet_pred_tiles"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:52:04.425471Z","iopub.status.busy":"2022-03-09T07:52:04.424715Z","iopub.status.idle":"2022-03-09T07:52:05.814732Z","shell.execute_reply":"2022-03-09T07:52:05.813857Z","shell.execute_reply.started":"2022-03-09T07:52:04.425415Z"},"trusted":true},"outputs":[],"source":["vgg16_unet.load_weights(\"./Output/vgg16_unet.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T07:52:09.815961Z","iopub.status.busy":"2022-03-09T07:52:09.815115Z","iopub.status.idle":"2022-03-09T08:39:01.487425Z","shell.execute_reply":"2022-03-09T08:39:01.486277Z","shell.execute_reply.started":"2022-03-09T07:52:09.815913Z"},"trusted":true},"outputs":[],"source":["predict_on_tiles(tiles_dir=tiles_dir, model=vgg16_unet, save_dir='./vgg16_unet_pred_tiles/')"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2022-03-07T10:19:38.700898Z","iopub.status.busy":"2022-03-07T10:19:38.700058Z","iopub.status.idle":"2022-03-07T10:19:39.674239Z","shell.execute_reply":"2022-03-07T10:19:39.673211Z","shell.execute_reply.started":"2022-03-07T10:19:38.700846Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["!zip -r vgg16_unet_pred_tiles_v2.zip './vgg16_unet_pred_tiles'\n","!mkdir vgg16_stitched_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-09T08:40:00.45985Z","iopub.status.busy":"2022-03-09T08:40:00.459288Z","iopub.status.idle":"2022-03-09T08:41:03.204943Z","shell.execute_reply":"2022-03-09T08:41:03.204141Z","shell.execute_reply.started":"2022-03-09T08:40:00.459806Z"},"trusted":true},"outputs":[],"source":["vgg16_unet_tile = stitch_tiles(pred_tiles_dir=vgg16_unet_pred_tiles, save_filename='vgg16_unet_jp22', save_dir='./vgg16_stitched_pred/')"]},{"cell_type":"markdown","metadata":{},"source":["## MobileNetV2-UNet Semantic Maps Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T16:00:42.500144Z","iopub.status.busy":"2022-03-07T16:00:42.499539Z","iopub.status.idle":"2022-03-07T16:00:43.306645Z","shell.execute_reply":"2022-03-07T16:00:43.305327Z","shell.execute_reply.started":"2022-03-07T16:00:42.500092Z"},"trusted":true},"outputs":[],"source":["!mkdir mobilenetv2_unet_pred_tiles"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T16:01:11.388718Z","iopub.status.busy":"2022-03-07T16:01:11.388375Z","iopub.status.idle":"2022-03-07T16:01:12.723535Z","shell.execute_reply":"2022-03-07T16:01:12.722498Z","shell.execute_reply.started":"2022-03-07T16:01:11.388685Z"},"trusted":true},"outputs":[],"source":["mobilenetv2_unet.load_weights(\"./Output/mobilenetv2_unet.h5\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T16:01:15.411212Z","iopub.status.busy":"2022-03-07T16:01:15.410887Z","iopub.status.idle":"2022-03-07T16:02:51.481591Z","shell.execute_reply":"2022-03-07T16:02:51.480363Z","shell.execute_reply.started":"2022-03-07T16:01:15.411178Z"},"trusted":true},"outputs":[],"source":["predict_on_tiles(tiles_dir=tiles_dir, model=mobilenetv2_unet, save_dir='./mobilenetv2_unet_pred_tiles/')"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2022-03-07T16:02:51.484071Z","iopub.status.busy":"2022-03-07T16:02:51.483662Z","iopub.status.idle":"2022-03-07T16:02:53.482148Z","shell.execute_reply":"2022-03-07T16:02:53.480702Z","shell.execute_reply.started":"2022-03-07T16:02:51.484025Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["!zip -r mobilenetv2_unet_pred_tiles.zip './mobilenetv2_unet_pred_tiles'\n","!mkdir mobilenetv2_unet_stitched_pred"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-03-07T16:02:58.688875Z","iopub.status.busy":"2022-03-07T16:02:58.688562Z","iopub.status.idle":"2022-03-07T16:03:00.986911Z","shell.execute_reply":"2022-03-07T16:03:00.985839Z","shell.execute_reply.started":"2022-03-07T16:02:58.688842Z"},"trusted":true},"outputs":[],"source":["mobilenetv2_unet_tile = stitch_tiles(pred_tiles_dir='./mobilenetv2_unet_pred_tiles/', save_filename='mobilenetv2_unet_jp22', save_dir='./mobilenetv2_unet_stitched_pred/')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":4}
